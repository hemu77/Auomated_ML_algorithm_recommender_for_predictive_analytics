# -*- coding: utf-8 -*-
"""hemu (1).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1VpXU1sKGf9sPVAOdEFoYlsFQGWY24w1u
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, r2_score
from sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder
from sklearn.impute import SimpleImputer
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor
from sklearn.linear_model import LogisticRegression, LinearRegression
from sklearn.svm import SVC, SVR
from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor
from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor
from sklearn.naive_bayes import GaussianNB
from scipy.sparse import issparse

def read_and_convert_dataset(file_path):
    if file_path.endswith('.csv'):
        data = pd.read_csv(file_path)
    elif file_path.endswith('.json'):
        data = pd.read_json(file_path)
    elif file_path.endswith('.xlsx') or file_path.endswith('.xls'):
        data = pd.read_excel(file_path, engine='openpyxl')
    else:
        raise ValueError("Unsupported file format. Please provide a CSV, JSON, or Excel file.")

    # Convert to CSV if not already
    if not file_path.endswith('.csv'):
        new_file_path = file_path.rsplit('.', 1)[0] + '.csv'
        data.to_csv(new_file_path, index=False)
        print(f"Converted file saved as {new_file_path}")
        return data, new_file_path
    return data, file_path

def preprocess_dataset(data):
    X = data.iloc[:, :-1]
    y = data.iloc[:, -1]

    categorical_features = X.select_dtypes(include=['object', 'bool']).columns.tolist()
    numeric_features = X.select_dtypes(include=['int64', 'float64']).columns.tolist()

    preprocessor = ColumnTransformer(transformers=[
        ('num', Pipeline(steps=[('imputer', SimpleImputer(strategy='mean')),
                                ('scaler', StandardScaler())]), numeric_features),
        ('cat', Pipeline(steps=[('imputer', SimpleImputer(strategy='most_frequent')),
                                ('encoder', OneHotEncoder(handle_unknown='ignore'))]), categorical_features)
    ])

    X_processed = preprocessor.fit_transform(X)
    if issparse(X_processed):
        X_processed = X_processed.toarray()

    if y.dtype == object or y.dtype == bool:
        y = LabelEncoder().fit_transform(y)

    return X_processed, y

def identify_task(y):
    if len(np.unique(y)) <= 2 or y.dtype == object:
        return 'classification'
    return 'regression'

def recommend_models(task):
    if task == 'classification':
        models = [RandomForestClassifier(), LogisticRegression(), SVC(), KNeighborsClassifier(), DecisionTreeClassifier(), GaussianNB()]
    else:  # regression
        models = [RandomForestRegressor(), LinearRegression(), SVR(), KNeighborsRegressor(), DecisionTreeRegressor()]
    return models

def evaluate_models(models, X_train, X_test, y_train, y_test, task):
    results = {}
    print("\nEvaluating models...")
    for model in models:
        model_name = model.__class__.__name__
        model.fit(X_train, y_train)
        y_pred = model.predict(X_test)
        score = accuracy_score(y_test, y_pred) if task == 'classification' else r2_score(y_test, y_pred)
        print(f"{model_name} {'Accuracy' if task == 'classification' else 'R2 Score'}: {score:.4f}")
        results[model_name] = score

    best_model = max(results, key=results.get)
    print(f"\nBest Model: {best_model} with {'Accuracy' if task == 'classification' else 'R2 Score'}: {results[best_model]:.4f}")
    return best_model, results[best_model]

if __name__ == "__main__":
    file_path = input("Please enter the path to your dataset file: ")
    data, _ = read_and_convert_dataset(file_path)
    X, y = preprocess_dataset(data)
    task = identify_task(y)
    print(f"\nTask identified as: {task}")
    models = recommend_models(task)
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    best_model, best_score = evaluate_models(models, X_train, X_test, y_train, y_test, task)
    print(f"\nBest model for {task}: {best_model} with a score of: {best_score:.4f}")

